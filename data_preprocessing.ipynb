{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e301508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd830da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epic-kitchens-100-annotations dataset\n",
    "def columnStringToInt(row):\n",
    "    strat_index = row['narration_id'].rindex('_') + 1\n",
    "    return int(row['narration_id'][strat_index:len(row['narration_id'])])\n",
    "\n",
    "def preprocess_raw_data_to_create_prompts(file_name:str):\n",
    "    prompt = []\n",
    "    separator = '=>'\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['narration_id_int'] = df.apply(lambda row: columnStringToInt(row), axis=1)\n",
    "    participants_ids = df['participant_id'].unique()\n",
    "    for participant_id in participants_ids:\n",
    "        filtered_df_by_participant_id = df[df['participant_id'] == participant_id] \n",
    "        video_ids = filtered_df_by_participant_id['video_id'].unique()\n",
    "        start_index = video_ids[0].index('_') + 1\n",
    "        video_ids_modified = [int(video_ids[i][start_index:len(video_ids[i])]) for i in range(len(video_ids))]\n",
    "        video_ids_modified = np.sort(video_ids_modified)\n",
    "        for video_id_int in video_ids_modified:\n",
    "            video_id_str = ''\n",
    "            if video_id_int <= 9:\n",
    "                video_id_str = '0' + str(video_id_int)\n",
    "            else:\n",
    "                video_id_str = str(video_id_int)\n",
    "            video_id_str = participant_id + \"_\" + video_id_str\n",
    "            filtered_df_by_video_id = filtered_df_by_participant_id[filtered_df_by_participant_id['video_id'] == video_id_str] \n",
    "            sorted_df_by_narration_id = filtered_df_by_video_id.sort_values(by=['narration_id_int'])\n",
    "            prompt_str = separator.join(sorted_df_by_narration_id['narration'])\n",
    "            prompt.append(prompt_str)\n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bfe2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = 'epic_kitchens_train_data.csv'\n",
    "train_prompts = preprocess_raw_data_to_create_prompts(train_file_name)\n",
    "with open('epic_kitchens_train_prompt.txt', 'w') as f:\n",
    "    for prompt in train_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "validation_file_name = 'epic_kitchens_validation_data.csv'\n",
    "validation_prompts = preprocess_raw_data_to_create_prompts(validation_file_name)\n",
    "with open('epic_kitchens_validation_prompt.txt', 'w') as f:\n",
    "    for prompt in validation_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "test_file_name = 'epic_kitchens_test_data.csv'\n",
    "test_prompts = preprocess_raw_data_to_create_prompts(test_file_name)\n",
    "with open('epic_kitchens_test_prompt.txt', 'w') as f:\n",
    "    for prompt in test_prompts:\n",
    "        f.write(f\"{prompt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f89b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VirtualHome datatset\n",
    "separator = '=>'\n",
    "prompts = []\n",
    "\n",
    "with open('virtual_home_actions.json', 'r') as f:\n",
    "    raw_action_list = json.load(f)\n",
    "\n",
    "actions_list = [raw_action.split('\\n') for raw_action in raw_action_list]\n",
    "for action_list in actions_list:\n",
    "    raw_steps = [action.split('\\n') for action in action_list]\n",
    "    steps = []\n",
    "    for raw_step in raw_steps:\n",
    "        start_index = raw_step[0].index(':') + 1\n",
    "        end_index = len(raw_step[0])\n",
    "        steps.append(raw_step[0][start_index: end_index].strip())\n",
    "    steps=steps[1:len(steps)]\n",
    "    prompt_str = separator.join(steps)\n",
    "    prompts.append(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_file_name = 'virtual_home_train_prompt.txt'\n",
    "validation_prompt_file_name = 'virtual_home_validation_prompt.txt'\n",
    "test_prompt_file_name = 'virtual_home_test_prompt.txt'\n",
    "\n",
    "#train_validation_test_split = 60,20,20\n",
    "total = len(prompts)\n",
    "train_percentage = 60\n",
    "validation_percentage = 20\n",
    "test_percentage = 20\n",
    "index_train = int(total * train_percentage / 100)\n",
    "index_validation = int(total * validation_percentage / 100)\n",
    "index_text = int(total * test_percentage / 100)\n",
    "\n",
    "train_prompts = prompts[0:index_train]\n",
    "validation_prompts = prompts[index_train + 1: index_train + index_validation]\n",
    "test_prompts = prompts[index_train + index_validation + 1: total]\n",
    "\n",
    "\n",
    "with open(train_prompt_file_name, 'w') as f:\n",
    "    for prompt in train_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "with open(validation_prompt_file_name, 'w') as f:\n",
    "    for prompt in validation_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "        \n",
    "with open(test_prompt_file_name, 'w') as f:\n",
    "    for prompt in test_prompts:\n",
    "        f.write(f\"{prompt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb0c461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-Grained-R2R\n",
    "def preprocess_raw_json_data_to_create_prompts(file_name):\n",
    "    prompts = []\n",
    "    separator = '=>'\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        raw_action_list = json.load(f)\n",
    "\n",
    "    for raw_action in raw_action_list:\n",
    "        new_instructions = literal_eval(raw_action['new_instructions'])\n",
    "        steps = []\n",
    "        for instruction in new_instructions:\n",
    "            temp_instruction = ' '.join(instruction[0])\n",
    "            steps.append(temp_instruction)\n",
    "        prompt_str = separator.join(steps)\n",
    "        prompts.append(prompt_str)\n",
    "    return prompts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4263feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name_Fine_Grained_R2R = 'FGR2R_train.json'\n",
    "test_file_name_Fine_Grained_R2R = 'FGR2R_test.json'\n",
    "validation_file_name_Fine_Grained_R2R = 'FGR2R_validation.json'\n",
    "\n",
    "train_prompts = preprocess_raw_json_data_to_create_prompts(train_file_name_Fine_Grained_R2R)\n",
    "test_prompts = preprocess_raw_json_data_to_create_prompts(test_file_name_Fine_Grained_R2R)\n",
    "validation_prompts = preprocess_raw_json_data_to_create_prompts(validation_file_name_Fine_Grained_R2R)\n",
    "\n",
    "train_prompt_Fine_Grained_R2R_file_name = 'FGR2R_train_prompt.txt'\n",
    "validation_prompt_Fine_Grained_R2R_file_name = 'FGR2R_validation_prompt.txt'\n",
    "test_prompt_file_Fine_Grained_R2R_name = 'FGR2R_test_prompt.txt'\n",
    "\n",
    "with open(train_prompt_Fine_Grained_R2R_file_name, 'w') as f:\n",
    "    for prompt in train_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "\n",
    "with open(validation_prompt_Fine_Grained_R2R_file_name, 'w') as f:\n",
    "    for prompt in validation_prompts:\n",
    "        f.write(f\"{prompt}\\n\")\n",
    "        \n",
    "with open(test_prompt_file_Fine_Grained_R2R_name, 'w') as f:\n",
    "    for prompt in test_prompts:\n",
    "        f.write(f\"{prompt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987dfba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
